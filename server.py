import asyncio
import websockets
import json
import logging
import base64
import wave
import io
import os
import time
from concurrent.futures import ThreadPoolExecutor

# AI ç›¸å…³ä¾èµ–
from openai import AsyncOpenAI
from faster_whisper import WhisperModel
import edge_tts

# ============================================================
#  SDUI Gateway Server â€” DeepSeek AI è¯­éŸ³å¯¹è¯ç»ˆç«¯
# ============================================================
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s'
)
logging.getLogger("websockets").setLevel(logging.WARNING)

# ---- AI å¼•æ“é…ç½® ----
# 1. DeepSeek API é…ç½® (è¯·æ›¿æ¢ä¸ºæ‚¨è‡ªå·±çš„ API KEY)
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY", "sk-ce6b2df0dfa6455e9c862f033dbbb16b")
aclient = AsyncOpenAI(api_key=DEEPSEEK_API_KEY, base_url="https://api.deepseek.com")

# 2. Faster-Whisper æœ¬åœ° STT é…ç½®
logging.info("â³ æ­£åœ¨åŠ è½½æœ¬åœ° Whisper STT æ¨¡å‹...")
# ä½¿ç”¨ CPU å’Œ int8 é‡åŒ–ï¼Œä¿è¯åœ¨æ™®é€šæœºå™¨ä¸Šä¹Ÿæœ‰æå¿«çš„æ¨ç†é€Ÿåº¦
whisper_model = WhisperModel("base", device="cpu", compute_type="int8")
executor = ThreadPoolExecutor(max_workers=4)
logging.info("âœ… STT æ¨¡å‹åŠ è½½å®Œæ¯•")

# ---- å¤šç»ˆç«¯è®¾å¤‡æ³¨å†Œè¡¨ä¸ Session çŠ¶æ€ ----
# key: device_id
# value: { "ws": ws, "addr": addr, "telemetry": {}, "audio_buffer": bytearray, 
#          "messages": [], "stats": {"rounds": 0, "total_tokens": 0} }
devices: dict = {}

def get_or_create_device(device_id, websocket, remote):
    if device_id not in devices:
        devices[device_id] = {
            "ws": websocket,
            "addr": str(remote),
            "telemetry": {},
            "last_seen": time.strftime("%H:%M:%S"),
            "audio_buffer": bytearray(), # æ¯ä¸ªè®¾å¤‡ç‹¬ç«‹çš„éŸ³é¢‘ç¼“å†²
            "messages": [],              # å¤šè½®å¯¹è¯å†å²
            "stats": {"rounds": 0, "total_tokens": 0} # ç»Ÿè®¡æ•°æ®
        }
    else:
        devices[device_id]["ws"] = websocket
        devices[device_id]["addr"] = str(remote)
    return devices[device_id]


# ============================================================
#  UI å¸ƒå±€æ„å»ºå™¨ (SDUI å¼•æ“)
# ============================================================
def build_chat_bubble(text, is_user=False):
    """æ„å»ºå•æ¡èŠå¤©æ°”æ³¡ UI"""
    bg_color = "#2ecc71" if is_user else "#333333" # ç”¨æˆ·ç»¿è‰²ï¼ŒAIæ·±ç°
    text_color = "#ffffff"
    # SDUI ä¸­çš„ long_mode è®¾ä¸º scroll å¯ä»¥è®©é•¿æ–‡æœ¬åœ¨æ°”æ³¡å†…æ»šåŠ¨ï¼Œé¿å…æ’‘çˆ†å®¹å™¨
    return {
        "type": "container",
        "w": "full",
        "h": "content",
        "bg_color": bg_color,
        "radius": 10,
        "pad": 10,
        "flex": "column",
        "justify": "center",
        "children": [
            {
                "type": "label",
                "text": text,
                "font_size": 16,
                "text_color": text_color,
                "w": "full",
                "long_mode": "scroll"
            }
        ]
    }

def build_ai_layout(device_state):
    """æ„å»ºæ²‰æµ¸å¼ AI å¯¹è¯ç»ˆç«¯å¸ƒå±€"""
    stats = device_state["stats"]
    messages = device_state["messages"]
    
    # æŠ½å–éœ€è¦å±•ç¤ºçš„å¯¹è¯è®°å½• (è¿‡æ»¤æ‰ system prompt)
    display_msgs = [m for m in messages if m["role"] != "system"]
    
    # æ¸²æŸ“å†å²å¯¹è¯æ°”æ³¡
    bubble_children = []
    if not display_msgs:
        bubble_children.append({
            "type": "label",
            "text": "è¯·æŒ‰ä½åº•éƒ¨æŒ‰é’®å¼€å§‹å¯¹è¯...",
            "font_size": 16,
            "text_color": "#888888",
            "align": "center"
        })
    else:
        for msg in display_msgs:
            bubble_children.append(build_chat_bubble(msg["content"], is_user=(msg["role"]=="user")))

    # æ„å»ºå®Œæ•´ JSON æ ‘
    return {
        "flex": "column",
        "justify": "start",
        "align_items": "center",
        "gap": 10,
        "children": [
            # 1. é¡¶éƒ¨çŠ¶æ€æ 
            {
                "type": "label",
                "id": "status_label",
                "text": "ğŸŸ¢ ç³»ç»Ÿå°±ç»ªï¼Œç­‰å¾…å”¤é†’",
                "font_size": 16,
                "text_color": "#f1c40f"
            },
            # 2. ç»Ÿè®¡ä¿¡æ¯æ 
            {
                "type": "container",
                "flex": "row",
                "justify": "space_between",
                "w": "90%",
                "h": 30,
                "children": [
                    {"type": "label", "text": f"ğŸ’¬ è½®æ•°: {stats['rounds']}", "font_size": 14, "text_color": "#aaaaaa"},
                    {"type": "label", "text": f"ğŸª™ Tokens: {stats['total_tokens']}", "font_size": 14, "text_color": "#aaaaaa"}
                ]
            },
            # 3. å¯¹è¯å†å²æ»šåŠ¨åŒº
            {
                "type": "container",
                "id": "scroll_box",
                "scrollable": True,
                "w": "95%", 
                "h": 260, # ç»™åº•éƒ¨ç•™å‡ºç©ºé—´
                "flex": "column", 
                "gap": 10,
                "bg_color": "#111111", 
                "pad": 10, 
                "radius": 10,
                "children": bubble_children
            },
            # 4. åº•éƒ¨äº¤äº’æ§åˆ¶åŒº
            {
                "type": "container",
                "flex": "row",
                "gap": 20,
                "w": "full",
                "justify": "center",
                "children": [
                    {
                        "type": "button",
                        "id": "btn_new_chat",
                        "text": "ğŸ”„ æ–°å¯¹è¯",
                        "w": 100, "h": 50,
                        "bg_color": "#e74c3c",
                        "radius": 25,
                        "on_click": "server://ui/new_chat"
                    },
                    {
                        "type": "button",
                        "id": "btn_rec",
                        "text": "ğŸ™ï¸ æŒ‰ä½è¯´è¯",
                        "w": 140, "h": 50,
                        "bg_color": "#3498db",
                        "radius": 25,
                        "on_press": "local://audio/cmd/record_start",
                        "on_release": "local://audio/cmd/record_stop",
                        # æŒ‰ä¸‹æ—¶çš„å‘¼å¸åŠ¨ç”»
                        "anim": {"type": "color_pulse", "color_a": "#3498db", "color_b": "#2980b9", "duration": 800, "repeat": -1}
                    }
                ]
            }
        ]
    }

# ============================================================
#  è¾…åŠ©å‘é€å‡½æ•°
# ============================================================
async def send_topic(ws, topic: str, payload):
    msg = json.dumps({"topic": topic, "payload": payload}, ensure_ascii=False)
    await ws.send(msg)

async def send_layout(ws, layout: dict):
    await send_topic(ws, "ui/layout", layout)

async def send_update(ws, widget_id: str, **props):
    update = {"id": widget_id, **props}
    await send_topic(ws, "ui/update", update)

# ============================================================
#  AI ä¸šåŠ¡æµæ°´çº¿ (STT -> LLM -> TTS)
# ============================================================
def stt_task(audio_bytes):
    """[åŒæ­¥ä»»åŠ¡] ä¾›çº¿ç¨‹æ± è°ƒç”¨ï¼šå°†å­—èŠ‚æµå†™å…¥ä¸´æ—¶æ–‡ä»¶å¹¶ä½¿ç”¨ faster-whisper è¯†åˆ«"""
    tmp_file = f"tmp_stt_{time.time()}.wav"
    try:
        with wave.open(tmp_file, 'wb') as f:
            f.setnchannels(1)
            f.setsampwidth(2)
            f.setframerate(22050) # åŒ¹é… ESP32 é»˜è®¤å½•éŸ³é¢‘ç‡
            f.writeframes(audio_bytes)
        
        # çº¯æœ¬åœ°è¯†åˆ«
        segments, info = whisper_model.transcribe(tmp_file, beam_size=5, language="zh")
        text = "".join([s.text for s in segments])
        return text.strip()
    finally:
        if os.path.exists(tmp_file):
            os.remove(tmp_file)

async def process_chat_round(ws, device_id, device_state):
    """æ ¸å¿ƒ AI é—®ç­”æµæ°´çº¿"""
    audio_data = bytes(device_state["audio_buffer"])
    device_state["audio_buffer"].clear()
    
    if len(audio_data) < 10000: # æŠ›å¼ƒè¿‡çŸ­çš„æ— æ„è§¦ç¢° (çº¦0.5ç§’)
        await send_update(ws, "status_label", text="ğŸŸ¢ ç­‰å¾…å”¤é†’...")
        return

    # --- ä¿å­˜ debug WAV ä¾¿äºè°ƒè¯• ---
    debug_filename = f"debug_recv_{device_id}.wav"
    try:
        with wave.open(debug_filename, 'wb') as f:
            f.setnchannels(1)
            f.setsampwidth(2)
            f.setframerate(22050) # åŒ¹é… ESP32 é»˜è®¤å½•éŸ³é¢‘ç‡
            f.writeframes(audio_data)
        logging.info(f"[{device_id}] ğŸ’¾ è°ƒè¯•éŸ³é¢‘å·²ä¿å­˜ â†’ {os.path.abspath(debug_filename)}")
    except Exception as e:
        logging.error(f"[{device_id}] âœ— æ— æ³•ä¿å­˜è°ƒè¯•éŸ³é¢‘: {e}")

    try:
        # 1. æœ¬åœ° STT (æ”¾åˆ°çº¿ç¨‹æ± ä¸­é˜²é˜»å¡å¼‚æ­¥å¾ªç¯)
        await send_update(ws, "status_label", text="ğŸ™ï¸ æ­£åœ¨è¯†åˆ«...")
        loop = asyncio.get_running_loop()
        user_text = await loop.run_in_executor(executor, stt_task, audio_data)
        
        if not user_text:
            logging.warning(f"[{device_id}] STT è¯†åˆ«ä¸ºç©º")
            await send_update(ws, "status_label", text="âš ï¸ æœªå¬åˆ°å£°éŸ³ï¼Œè¯·é‡è¯•")
            return

        logging.info(f"[{device_id}] ç”¨æˆ·: {user_text}")
        
        # å­˜å…¥ä¸Šä¸‹æ–‡å¹¶åˆ·æ–° UI (å±•ç¤ºç”¨æˆ·æé—®æ°”æ³¡)
        device_state["messages"].append({"role": "user", "content": user_text})
        await send_layout(ws, build_ai_layout(device_state))
        
        # 2. DeepSeek å¤§æ¨¡å‹è¯·æ±‚
        await send_update(ws, "status_label", text="ğŸ§  DeepSeek æ€è€ƒä¸­...")
        
        # å¦‚æœæ˜¯é¦–æ¬¡å¯¹è¯ï¼Œæ³¨å…¥ç³»ç»Ÿæç¤ºè¯
        if not any(m["role"] == "system" for m in device_state["messages"]):
            device_state["messages"].insert(0, {
                "role": "system", 
                "content": "ä½ æ˜¯è¿è¡Œåœ¨ ESP32 æ™ºèƒ½ç»ˆç«¯ä¸Šçš„è¯­éŸ³åŠ©æ‰‹ï¼Œè¯·ç”¨ç®€çŸ­ã€è‡ªç„¶ã€å£è¯­åŒ–çš„ä¸­æ–‡å›ç­”ç”¨æˆ·ã€‚"
            })

        response = await aclient.chat.completions.create(
            model="deepseek-chat",
            messages=device_state["messages"]
        )
        
        ai_text = response.choices[0].message.content
        used_tokens = response.usage.total_tokens
        
        logging.info(f"[{device_id}] AI: {ai_text} (æ¶ˆè€— {used_tokens} tokens)")
        
        # è®°å½•çŠ¶æ€å¹¶åˆ·æ–° UI (å±•ç¤º AI å›å¤æ°”æ³¡å’ŒçŠ¶æ€æ›´æ–°)
        device_state["messages"].append({"role": "assistant", "content": ai_text})
        device_state["stats"]["rounds"] += 1
        device_state["stats"]["total_tokens"] += used_tokens
        await send_layout(ws, build_ai_layout(device_state))
        
        # 3. Edge-TTS åˆæˆå¹¶ä¸‹å‘æµ
        await send_update(ws, "status_label", text="ğŸ”Š æ­£åœ¨æ’­æ”¾...")
        
        # ESP32 é»˜è®¤ I2S é©±åŠ¨èƒ½å®Œç¾æ’­æ”¾ 16bit-Mono PCM æµï¼Œæˆ‘ä»¬å°† edge-tts æ ¼å¼ä¸ä¹‹åŒ¹é…
        communicate = edge_tts.Communicate(
            text=ai_text, 
            voice="zh-CN-XiaoxiaoNeural", # å¾®è½¯ä¼˜è´¨ä¸­æ–‡å¥³å£°
            rate="+10%",                  # ç¨å¾®åŠ å¿«ä¸€ç‚¹è¯­é€Ÿæ˜¾å¾—æ›´æ™ºèƒ½
            output_format="raw-16khz-16bit-mono-pcm" 
        )
        
        chunk_buffer = bytearray()
        async for chunk in communicate.stream():
            if chunk["type"] == "audio":
                chunk_buffer.extend(chunk["data"])
                
                # æ¯ç§¯ç´¯çº¦ 2KB ä¸‹å‘ä¸€æ¬¡åˆ‡ç‰‡ (é¿å…ç»ˆç«¯å†…å­˜ OOM)
                if len(chunk_buffer) >= 2048:
                    b64_chunk = base64.b64encode(chunk_buffer).decode('utf-8')
                    await send_topic(ws, "audio/play", b64_chunk)
                    chunk_buffer.clear()
                    await asyncio.sleep(0.01) # ç•¥å¾®è®©æ¸¡ CPU é˜²ç½‘ç»œæ‹¥å¡

        # å‘é€å‰©ä½™çš„åˆ‡ç‰‡
        if len(chunk_buffer) > 0:
            b64_chunk = base64.b64encode(chunk_buffer).decode('utf-8')
            await send_topic(ws, "audio/play", b64_chunk)

        await send_update(ws, "status_label", text="ğŸŸ¢ ç³»ç»Ÿå°±ç»ªï¼Œç­‰å¾…å”¤é†’")

    except Exception as e:
        logging.error(f"[{device_id}] Pipeline Error: {e}")
        await send_update(ws, "status_label", text="âŒ å‘ç”Ÿé”™è¯¯ï¼Œè¯·é‡è¯•")


# ============================================================
#  WebSocket ä¸»è·¯ç”±ç½‘å…³
# ============================================================
async def sdui_handler(websocket):
    remote = websocket.remote_address
    connection_device_id = None
    logging.info(f"âœ¦ ç»ˆç«¯å·²è¿æ¥: {remote}")

    try:
        async for message in websocket:
            try:
                data = json.loads(message)
            except json.JSONDecodeError:
                continue

            topic = data.get("topic")
            payload = data.get("payload", {})
            msg_device_id = data.get("device_id") or connection_device_id or "UNKNOWN"
            
            # åˆå§‹åŒ–ä¸è®¾å¤‡çŠ¶æ€ç»‘å®š
            if msg_device_id != "UNKNOWN":
                connection_device_id = msg_device_id
                device_state = get_or_create_device(msg_device_id, websocket, remote)
            
            # ==== 1. è®¾å¤‡é¥æµ‹å¿ƒè·³ (å»ºè¿ä¸ä¿æ´») ====
            if topic == "telemetry/heartbeat":
                if msg_device_id == "UNKNOWN" and isinstance(payload, dict):
                    msg_device_id = payload.get("device_id", "UNKNOWN")
                    connection_device_id = msg_device_id
                    device_state = get_or_create_device(msg_device_id, websocket, remote)
                
                device_state["telemetry"] = payload
                device_state["last_seen"] = time.strftime("%H:%M:%S")
                
                # é¦–æ¬¡æ”¶åˆ°å¿ƒè·³ï¼Œä¸‹å‘å®Œæ•´ AI äº¤äº’ç•Œé¢
                if not hasattr(websocket, 'initialized'):
                    websocket.initialized = True
                    await send_layout(websocket, build_ai_layout(device_state))
                continue

            if not connection_device_id or connection_device_id == "UNKNOWN":
                continue # æœªæ³¨å†Œçš„æ— æ•ˆè¯·æ±‚

            # ==== 2. éŸ³é¢‘é“¾è·¯ ====
            if topic == "audio/record":
                state = payload.get("state")
                if state == "start":
                    device_state["audio_buffer"].clear()
                    await send_update(websocket, "status_label", text="ğŸ‘‚ å½•éŸ³ä¸­...")
                    # ä¹Ÿå¯ä»¥ç»™ç•Œé¢çš„æŸä¸ªå…ƒç´ åŠ ç‚¹åŠ¨ç”»
                    await send_update(websocket, "scroll_box", anim={"type": "breathe", "min_opa": 180, "max_opa": 255, "duration": 1000})

                elif state == "stream":
                    b64_data = payload.get("data", "")
                    if b64_data:
                        device_state["audio_buffer"].extend(base64.b64decode(b64_data))

                elif state == "stop":
                    # åœæ­¢åŠ¨ç”»ï¼Œå¯åŠ¨å¤„ç†æµæ°´çº¿
                    await send_update(websocket, "scroll_box", anim={"type": "none"})
                    asyncio.create_task(process_chat_round(websocket, connection_device_id, device_state))

            # ==== 3. UI äº¤äº’è·¯ç”± ====
            elif topic == "ui/new_chat":
                logging.info(f"[{connection_device_id}] ç”¨æˆ·è¯·æ±‚å¼€å¯æ–°å¯¹è¯")
                # æ¸…ç†ä¸Šä¸‹æ–‡
                device_state["messages"].clear()
                device_state["stats"] = {"rounds": 0, "total_tokens": 0}
                # å…¨é‡ä¸‹å‘åˆ·æ–°å±å¹•
                await send_layout(websocket, build_ai_layout(device_state))

    except websockets.exceptions.ConnectionClosed:
        pass
    finally:
        logging.info(f"âœ¦ ç»ˆç«¯æ–­å¼€è¿æ¥: {remote}")
        if connection_device_id and connection_device_id in devices:
            devices[connection_device_id]["ws"] = None


async def main():
    server = await websockets.serve(sdui_handler, "0.0.0.0", 8080)
    logging.info("=========================================================")
    logging.info("  ğŸš€ SDUI DeepSeek AI Server started on ws://0.0.0.0:8080")
    logging.info("=========================================================")
    await asyncio.Future()

if __name__ == "__main__":
    asyncio.run(main())